{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9415fb12-6f34-46d4-8a28-b97c2790cc99",
   "metadata": {},
   "source": [
    "# COSC 437 Data Mining Lab Assignment 3 - Logistic Regression for Pulsar Classification\n",
    "\n",
    "## Data Information\n",
    "HTRU2 is a data set which describes a sample of pulsar candidates collected during the High Time Resolution Universe Survey (South). \n",
    "\n",
    "Pulsars are a rare type of Neutron star that produce radio emission detectable here on Earth. They are of considerable scientific interest as probes of space-time, the inter-stellar medium, and states of matter. \n",
    "\n",
    "As pulsars rotate, their emission beam sweeps across the sky, and when this crosses our line of sight, produces a detectable pattern of broadband radio emission. As pulsars\n",
    "rotate rapidly, this pattern repeats periodically. Thus pulsar search involves looking for periodic radio signals with large radio telescopes.\n",
    "\n",
    "Each pulsar produces a slightly different emission pattern, which varies slightly with each rotation. Thus a  potential signal detection known as a 'candidate', is averaged over many rotations of the pulsar, as determined by the length of an observation. In the absence of additional info, each candidate could potentially describe a real pulsar. However in practice almost all detections are caused by radio frequency interference (RFI) and noise, making legitimate signals hard to find.\n",
    "\n",
    "Machine learning tools are now being used to automatically label pulsar candidates to facilitate rapid analysis. Classification systems in particular are being widely adopted, which treat the candidate data sets  as binary classification problems. Here the legitimate pulsar examples are a minority positive class, and spurious examples the majority negative class. At present multi-class labels are unavailable, given the costs associated with data annotation.\n",
    "\n",
    "The data set shared here contains 16,259 spurious examples caused by RFI/noise, and 1,639 real pulsar examples. These examples have all been checked by human annotators. \n",
    "\n",
    "## Variable Description\n",
    "| Variable Name    | Role    | Type       | Description | Units | Missing Values |\n",
    "| ---------------- | ------- | ---------- | ----------- | ----- | -------------- |\n",
    "| Profile_mean     | Feature | Continuous |             |       | no             |\n",
    "| Profile_stdev    | Feature | Continuous |             |       | no             |\n",
    "| Profile_skewness | Feature | Continuous |             |       | no             |\n",
    "| Profile_kurtosis | Feature | Continuous |             |       | no             |\n",
    "| DM_mean          | Feature | Continuous |             |       | no             |\n",
    "| DM_stdev         | Feature | Continuous |             |       | no             |\n",
    "| DM_skewness      | Feature | Continuous |             |       | no             |\n",
    "| DM_kurtosis      | Feature | Continuous |             |       | no             |\n",
    "| class            | Target  | Binary     |             |       | no             |\n",
    "\n",
    "\n",
    "## Lab Overview\n",
    "In this lab, you will apply logistic regression to the HTRU2 dataset to build a classification model. The goal is to predict whether a given candidate is a real pulsar (positive class) or spurious (negative class) using the provided features.\n",
    "\n",
    "\n",
    "## Part I - Data Loading and Exploration\n",
    "- Load the HTRU2 dataset into your environment. Perform an initial exploration of the dataset, including:\n",
    "- Basic statistics and the distributions of the features.\n",
    "- Distribution of the target class (ensure you note the imbalance between classes).\n",
    "- Check for missing values (there are none, but confirm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cac49e4-175d-4785-8d76-45f21e2dc563",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Your code here. If appropriate, use multiple code blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff4f43a-e618-4f05-842b-0bb64aca4f87",
   "metadata": {},
   "source": [
    "## Part II - Data Preprocessing\n",
    "Normalization: Since logistic regression has the best performance with normalized or standardized features. Scale the data using a method of your choice (e.g., min-max scaling or standardization).\n",
    "\n",
    "When you are done, split the data into a training set (80%) and a test set (20%). Given the class imbalance (90% negative class, 10% positive class), ensure both sets maintain this imbalance by setting stratify=y in the train_test_split function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c762d8-c4a7-4f2f-8c4a-cc9ad1f61840",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Your code here. If appropriate, use multiple code blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406f8ee3-e432-48f8-84c2-7f59e6db33be",
   "metadata": {},
   "source": [
    "## Part III - Logistic Regression Model\n",
    "Train a logistic regression model on the training data. Use LogisticRegression from sklearn.linear_model. Logistic regression works well when the classes are linearly separable or approximately so.\n",
    "\n",
    "After training the logistic regression model, extract and interpret the model coefficients. Print the model coefficients and interpret them. Map the coefficients to the corresponding feature names for clarity. In logistic regression, the coefficients indicate the weight (importance) of each feature in determining the outcome. Positive coefficients suggest that as the feature increases, the probability of the positive class (pulsar) increases, while negative coefficients suggest the opposite. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb41fb0-2e33-4bac-84b4-20bad2470503",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Your code here. If appropriate, use multiple code blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0c7ec3-db80-4da8-a117-239fca335cc3",
   "metadata": {},
   "source": [
    "## Part IV - Model Evaluation\n",
    "After training the model, it’s essential to assess its performance. Given that the pulsar data is highly imbalanced, evaluation metrics like accuracy alone are not sufficient. Focus on metrics that consider the model’s performance on both classes, particularly the minority class (pulsars).\n",
    "\n",
    "Use the test set to generate predictions.\n",
    "- `yhat_pred` contains the predicted labels (0 or 1).\n",
    "- `yhat_prob` contains the predicted probabilities, which can be used to adjust decision thresholds later if needed.\n",
    "\n",
    "### Metrics\n",
    "Calculate and interpret the following metrics to evaluate your logistic regression model:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-score\n",
    "- Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44455808-ab20-459f-8973-5282507ab27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO Calculate the metrics, save them in the variables below\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8d7cd7-f86d-4d78-b0fe-2a3179171fe6",
   "metadata": {},
   "source": [
    "### Imbalance Consideration\n",
    "Given the imbalance in the dataset (many more spurious examples than real pulsars), achieving high precision or recall can be difficult. Pay special attention to the recall of the minority class (pulsars) as it indicates the ability to detect true pulsars.\n",
    "\n",
    "As can be expected, missing any actual pulsars is more costly than misclassifying non-pulsars as pulsars. What other threshold should we choose? Visualize the model's behavior with a ROC curve. Pick a different threshold that will better find out pulsars without hurting the overall accuracy to much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254b1749-f8d1-402f-b31d-fc7e100ee210",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Your code here. If appropriate, use multiple code blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289d68dc-eabb-465a-8771-8ae62ad7a88f",
   "metadata": {},
   "source": [
    "## Part V - Handling Class Imbalance with Resampling\n",
    "Imbalanced datasets present a significant challenge in classification. Without addressing the imbalance, the model may be biased toward the majority class, leading to poor performance in identifying the minority class (real pulsars). Two strategies to handle this are using class weights or resampling.\n",
    "\n",
    "### Using Class Weights\n",
    "Logistic regression has an option to handle class imbalance by assigning different weights to classes. By setting `class_weight='balanced'`, the model will assign higher weight to the minority class (pulsars), which can help in identifying more pulsars.\n",
    "\n",
    "Once your the balanced model is trained, evaluate the model using the same metrics (accuracy, precision, recall, F1-score, confusion matrix) to see if the performance on the minority class improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63437b48-f626-48eb-96c7-7cf6335c1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Your code here. If appropriate, use multiple code blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b987297e-0c9a-46f8-8d57-433ff1d9a975",
   "metadata": {},
   "source": [
    "### Using Resampling\n",
    "Alternatively, you can resample the training data to either oversample the minority class or undersample the majority class. For this lab, just use oversampling. You may use the `RandomOverSampler` from the `imblearn` library to oversample your data before training.\n",
    "\n",
    "Once your the resampled model is trained, evaluate it using the same metrics and compare with the original and class-weighted models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa25349-b25e-4d1d-8860-81680ef3c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Your code here. If appropriate, use multiple code blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ae7848-6055-45ef-aaae-6a40db07311f",
   "metadata": {},
   "source": [
    "### Comparison and Discussion\n",
    "Compare the results of the three models (baseline, class-weighted, and resampled).\n",
    "- Which model performs best in terms of recall for the pulsar class?\n",
    "- Does resampling or using class weights improve the detection of pulsars?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eab6a3-3ec7-4911-bc4e-15647e385b88",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "- R. J. Lyon, B. W. Stappers, S. Cooper, J. M. Brooke, J. D. Knowles, Fifty Years of Pulsar Candidate Selection: From simple filters to a new principled real-time classification approach, Monthly Notices of the Royal Astronomical Society 459 (1), 1104-1123, DOI: 10.1093/mnras/stw656\n",
    "- R. J. Lyon, HTRU2, DOI: 10.6084/m9.figshare.3080389.v1.\n",
    "- https://archive.ics.uci.edu/dataset/372/htru2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
